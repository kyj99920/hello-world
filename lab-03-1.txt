import numpy as np
#numpy 라이브러리를 np라는 이름으로 반입

X = np.array([1, 2, 3])
Y = np.array([1, 2, 3])
#X와 Y값 배열
#랭크가 1인 배열을 생성

def cost_func(W, X, Y):
#cost function 정의
    cost = 0
    #cost = 0 으로 입력
    for i in range(len(X)):
        c += (W * X[i] - Y[i]) ** 2
    return c / len(X)

for feed_W in np.linspace(-3, 5, num=15):
    curr_cost = cost_func(feed_W, X, Y)
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost))

X = np.array([1, 2, 3])
Y = np.array([1, 2, 3])
#X와 Y 배열 정의
#nparray클래스는 데이터가 같은 자료형이어야함


def cost_func(W, X, Y):
#cost 함수 정의
  hypothesis = X * W
  return tf.reduce_mean(tf.square(hypothesis - Y))

W_values = np.linspace(-3, 5, num=15)
cost_values = []

for feed_W in W_values:
    curr_cost = cost_func(feed_W, X, Y)
    cost_values.append(curr_cost)
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost))

import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (8,6)

import matplotlib.pyplot as plt

plt.plot(W_values, cost_values, "b")
plt.ylabel('Cost(W)')
plt.xlabel('W')
plt.show()

tf.set_random_seed(0) 

x_data = [1., 2., 3., 4.]
y_data = [1., 3., 5., 7.]
#x_data 와 y_data 값 입력

W = tf.Variable(tf.random_normal([1], -100., 100.))
#변수를 의미하며 임의의 값을 지정

for step in range(300):
    hypothesis = W * X
    cost = tf.reduce_mean(tf.square(hypothesis - Y))

    alpha = 0.01
    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))
    descent = W - tf.multiply(alpha, gradient)
    W.assign(descent)
    
    if step % 10 == 0:
        print('{:5} | {:10.4f} | {:10.6f}'.format(
            step, cost.numpy(), W.numpy()[0]))

